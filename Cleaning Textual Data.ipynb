{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# 1.1 Imports"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ae011ffb4c4e6a46"
  },
  {
   "cell_type": "code",
   "execution_count": 1176,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-01-19T12:54:15.899412Z",
     "start_time": "2024-01-19T12:54:14.865959Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import ast\n",
    "from string import punctuation\n",
    "import emoji\n",
    "from googletrans import Translator, LANGUAGES\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1177,
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"siebert/sentiment-roberta-large-english\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"siebert/sentiment-roberta-large-english\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-19T12:54:23.901507Z",
     "start_time": "2024-01-19T12:54:14.870027Z"
    }
   },
   "id": "4cd9a2893220d19d"
  },
  {
   "cell_type": "code",
   "execution_count": 1178,
   "outputs": [
    {
     "data": {
      "text/plain": "[{'label': 'negative', 'score': 0.613193690776825}]"
     },
     "execution_count": 1178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "sa = pipeline('text-classification', model='CAMeL-Lab/bert-base-arabic-camelbert-da-sentiment')\n",
    "sentences = 'أنا لست بخير'\n",
    "sa(sentences)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-19T12:54:27.006021Z",
     "start_time": "2024-01-19T12:54:23.898054Z"
    }
   },
   "id": "bd96f141e496857b"
  },
  {
   "cell_type": "code",
   "execution_count": 1179,
   "outputs": [],
   "source": [
    "sentiment_analysis = pipeline(\"sentiment-analysis\",model=\"siebert/sentiment-roberta-large-english\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-19T12:54:41.655603Z",
     "start_time": "2024-01-19T12:54:27.004673Z"
    }
   },
   "id": "c1a8145943047628"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 1.2 Constants"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cf522777d63497a3"
  },
  {
   "cell_type": "code",
   "execution_count": 1180,
   "outputs": [],
   "source": [
    "TOKENS = ['EMOJI', 'MENTION', 'HASHTAG', 'URL']"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-19T12:54:41.669962Z",
     "start_time": "2024-01-19T12:54:41.654678Z"
    }
   },
   "id": "aea4d33e7d0fa479"
  },
  {
   "cell_type": "code",
   "execution_count": 1181,
   "outputs": [],
   "source": [
    "CONTRACTIONS = [\n",
    "    (\"dont\", \"do not\"), (\"didnt\", \"did not\"), (\"im\", \"i am \"), (\"arent\", \"are not\"),\n",
    "    (\"isnt\", \"is not\"), (\"ive\", \"i have\"), (\"theyd\", \"they would\"), (\"id\", \"i would\"),\n",
    "    (\"it's\", 'it is'), ('i’m', 'i am'), ('don’t', 'do not'), (\"cant\", \"cannot\"),\n",
    "    (\"wont\", \"will not\"), (\"wouldnt\", \"would not\"), (\"hasnt\", \"has not\"),\n",
    "    (\"havent\", \"have not\"), (\"hadnt\", \"had not\"), (\"don't\", \"do not\"),\n",
    "    (\"didn’t\", \"did not\"), (\"i'm\", \"i am\"), (\"i’m\", \"i am\"), (\"aren't\", \"are not\"),\n",
    "    (\"aren’t\", \"are not\"), (\"isn't\", \"is not\"), (\"isn’t\", \"is not\"), (\"i’ve\", \"i have\"),\n",
    "    (\"they'd\", \"they would\"), (\"they’d\", \"they would\"), (\"i'd\", \"i would\"),\n",
    "    (\"i’d\", \"i would\"), ('it’s', 'it is'), (\"can't\", \"cannot\"), (\"can’t\", \"cannot\"),\n",
    "    (\"won't\", \"will not\"), (\"won’t\", \"will not\"), (\"wouldn't\", \"would not\"),\n",
    "    (\"wouldn’t\", \"would not\"), (\"hasn't\", \"has not\"), (\"hasn’t\", \"has not\"),\n",
    "    (\"haven't\", \"have not\"), (\"haven’t\", \"have not\"), (\"hadn't\", \"had not\"),\n",
    "    (\"hadn’t\", \"had not\"), ('needn\\'t', 'need not')\n",
    "]\n",
    "\n",
    "NON_SPACED_CONTRACTIONS = [('\\t', ' '), ('\\n', ' '), ('-', ' '),\n",
    "('–', ' '), ('…', ' '), ('—', ' ')]\n",
    "\n",
    "NON_SPACED_CONTRACTIONS = dict(NON_SPACED_CONTRACTIONS)\n",
    "CONTRACTIONS = dict(CONTRACTIONS)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-19T12:54:41.674040Z",
     "start_time": "2024-01-19T12:54:41.668527Z"
    }
   },
   "id": "611f110f7fbaa154"
  },
  {
   "cell_type": "code",
   "execution_count": 1182,
   "outputs": [],
   "source": [
    "TEXTING_LANGUAGE = {\n",
    "    '1st': 'first',\n",
    "    '2nd': 'second',\n",
    "    '3rd': 'third',\n",
    "    'sec': 'second',\n",
    "    'secs': 'seconds',\n",
    "    'hrs': 'hours',\n",
    "    'hr': 'hour',\n",
    "    'mins': 'minutes',\n",
    "    'min': 'minute',\n",
    "    '24/7': 'twenty four seven',\n",
    "    'afaik': '[ABBREVIATION: as far as I know]',\n",
    "    'b4': '[ABBREVIATION: before]',\n",
    "    'bday': '[ABBREVIATION: birthday]',\n",
    "    'bff': '[ABBREVIATION: best friends forever]',\n",
    "    'brb': '[ABBREVIATION: be right back]',\n",
    "    'btw': '[ABBREVIATION: by the way]',\n",
    "    'cul8r': '[ABBREVIATION: see you later]',\n",
    "    'fomo': '[ABBREVIATION: fear of missing out]',\n",
    "    'gtg': '[ABBREVIATION: got to go]',\n",
    "    'hmu': '[ABBREVIATION: hit me up]',\n",
    "    'idr': '[ABBREVIATION: I do not remember]',\n",
    "    'idk': '[ABBREVIATION: I do not know]',\n",
    "    'idrk': '[ABBREVIATION: I do not really know]',\n",
    "    'idc': '[ABBREVIATION: I do not care]',\n",
    "    'idts': '[ABBERVIATION: I do not think so]',\n",
    "    'idt': '[ABBREVIATION: I do not think]',\n",
    "    'ily': '[ABBREVIATION: I love you]',\n",
    "    'ily2': '[ABBREVIATION: I love you too]',\n",
    "    'ilysm': '[ABBREVIATION: I love you so much]',\n",
    "    'imho': '[ABBREVIATION: in my humble opinion]',\n",
    "    'imo': '[ABBREVIATION: in my opinion]',\n",
    "    'irl': '[ABBREVIATION: in real life]',\n",
    "    'jk': '[ABBREVIATION: just kidding]',\n",
    "    'kms': '[ABBREVIATION: kill myself]',\n",
    "    'kys': '[ABBREVIATION: kill yourself]',\n",
    "    'lol': '[ABBREVIATION: laughing out loud]',\n",
    "    'lmfao': '[ABBREVIATION: laughing my a** off]',\n",
    "    'lmk': '[ABBREVIATION: let me know]',\n",
    "    'mcm': '[ABBREVIATION: man crush Monday]',\n",
    "    'nvm': '[ABBREVIATION: never mind]',\n",
    "    'ok': '[ABBREVIATION: okay]',\n",
    "    'omg': '[ABBREVIATION: oh my god]',\n",
    "    'pls': '[ABBREVIATION: please]',\n",
    "    'plz': '[ABBREVIATION: please]',\n",
    "    'rofl': '[ABBREVIATION: rolling on the floor laughing]',\n",
    "    'smh': '[ABBREVIATION: shaking my head]',\n",
    "    'tbh': '[ABBREVIATION: to be honest]',\n",
    "    'tbf': '[ABBREVIATION: to be fair]',\n",
    "    'tmrrw': '[ABBREVIATION: tomorrow]',\n",
    "    'tmrw': '[ABBREVIATION: tomorrow]',\n",
    "    'tbt': '[ABBREVIATION: throwback Thursday]',\n",
    "    'thx': '[ABBREVIATION: thanks]',\n",
    "    'ttyl': '[ABBREVIATION: talk to you later]',\n",
    "    'tmi': '[ABBREVIATION: too much information]',\n",
    "    'tyt': '[ABBREVIATION: take your time]',\n",
    "    'wtf': '[ABBREVIATION: what the f***]',\n",
    "    'wth': '[ABBREVIATION: what the hell]',\n",
    "    'wyd': '[ABBREVIATION: what are you doing]',\n",
    "    'yw': '[ABBREVIATION: you are welcome]',\n",
    "    '2moro': '[ABBREVIATION: tomorrow]',\n",
    "    '2nite': '[ABBREVIATION: tonight]',\n",
    "    'g2g': '[ABBREVIATION: got to go]',\n",
    "    'hbd': '[ABBREVIATION: happy birthday]',\n",
    "    'fr': '[ABBREVIATION: for real]',\n",
    "    'uni': '[ABBREVIATION: university]',\n",
    "    'wcw': '[ABBREVIATION: woman crush Wednesday]',\n",
    "    'srsly': '[ABBREVIATION: seriously]',\n",
    "    'nbd': '[ABBREVIATION: no big deal]',\n",
    "    'roflmao': '[ABBREVIATION: rolling on the floor laughing my a** off]',\n",
    "    'sry': '[ABBREVIATION: sorry]',\n",
    "    'tgif': '[ABBREVIATION: thank goodness it\\'s Friday]',\n",
    "    'wbu': '[ABBREVIATION: what about you]',\n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-19T12:54:41.701637Z",
     "start_time": "2024-01-19T12:54:41.681812Z"
    }
   },
   "id": "90ec884a732a55c5"
  },
  {
   "cell_type": "code",
   "execution_count": 1183,
   "outputs": [],
   "source": [
    "STOPWORDS = [\n",
    "    'like', 'she', 'he', 'him', 'her', 'the', 'this', 'that', 'those',\n",
    "    'and', 'or', 'but', 'not', 'in', 'on', 'at', 'with', 'by', 'for', 'to',\n",
    "    'of', 'an', 'is', 'was', 'were', 'am', 'are', 'be', 'been', 'being',\n",
    "    'it', 'its', 'you', 'your', 'yours', 'they', 'them', 'their', 'theirs',\n",
    "    'we', 'us', 'our', 'ours', 'me', 'my', 'mine', 'myself', 'you', 'your',\n",
    "    'yours', 'yourself', 'yourselves', 'itself', 'he', 'him', 'his', 'himself',\n",
    "    'she', 'her', 'hers', 'herself', 'they', 'them', 'their', 'theirs', 'themselves',\n",
    "    'out', 'enta', 'enty', ' a ', 'zy', 'zay', 'keda', 'to', 'from', 'wallah',\n",
    "    'wallahy', 'wallahi', 'wehyat', 'so', 'for', 'yet', 'tab', 'el', 'al', 'bas',\n",
    "    'ashan', '3ashan', 'mashi', 'mashy', 'a', 'got', 'get', 'went', 'goes', 'go', 'i',\n",
    "    'before', 'after', 'because', 'cause', 'cuz', 'cos', 'howa', 'heya', 'hwa', 'homa', 'hya',\n",
    "    'tamam', 'tayeb', 'او', 'أو', 'و'\n",
    "]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-19T12:54:41.701824Z",
     "start_time": "2024-01-19T12:54:41.690463Z"
    }
   },
   "id": "8adcd5e453922234"
  },
  {
   "cell_type": "code",
   "execution_count": 1184,
   "outputs": [],
   "source": [
    "UNNECESSARY_CHARACTERS = ['@', '#', '“', '‘', '”','’', '...', '—', '–','؟','…', '$', '%', '^', '&', '*', \n",
    "                          '(', ')', '_', '+', '=', '{', '}', '[', ']', '\\\\', '|', ':', ';', '\"', \"'\", \n",
    "                          '<', '>', ',', '.', '?', '/', '؛', ' ،', '≠', '≤', '≥', '«', '»', 'ـ', '٪']\n",
    "for character in punctuation:\n",
    "    UNNECESSARY_CHARACTERS.append(character)\n",
    "    \n",
    "UNNECESSARY_CHARACTERS = set(UNNECESSARY_CHARACTERS)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-19T12:54:41.701880Z",
     "start_time": "2024-01-19T12:54:41.696134Z"
    }
   },
   "id": "93dc246981a9c3ce"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 2. Read Data"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "39ff60fcd04cd0a1"
  },
  {
   "cell_type": "code",
   "execution_count": 1185,
   "outputs": [],
   "source": [
    "circle_tweets_df = pd.read_csv('circle_tweet_content.csv')\n",
    "likes_df = pd.read_csv('likes.csv')\n",
    "tweets_df = pd.read_csv('tweet_content.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-19T12:54:42.334150Z",
     "start_time": "2024-01-19T12:54:41.700507Z"
    }
   },
   "id": "2c24a93f4567338a"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 3. Defining Functions"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "de76bf9dc019e47b"
  },
  {
   "cell_type": "code",
   "execution_count": 1186,
   "outputs": [],
   "source": [
    "def convert_string_to_list(input_string):\n",
    "    '''\n",
    "    This function takes in a string and returns a list.\n",
    "    ---\n",
    "    Parameters:\n",
    "        input_string: str\n",
    "    ---\n",
    "    Returns:\n",
    "        output_list: list\n",
    "    '''\n",
    "    # Remove square brackets and single quotes from the input string\n",
    "    cleaned_string = input_string.replace(\"[\", \"\").replace(\"]\", \"\").replace(\"'\", \"\").lower()\n",
    "\n",
    "    # Split the cleaned string into a list using ', ' as the separator\n",
    "    output_list = cleaned_string.split(', ')\n",
    "    \n",
    "    if len(output_list) == 1 and output_list[0] == '':\n",
    "        output_list = []\n",
    "\n",
    "    return output_list"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-19T12:54:42.347017Z",
     "start_time": "2024-01-19T12:54:42.345460Z"
    }
   },
   "id": "736b5f3fca400b11"
  },
  {
   "cell_type": "code",
   "execution_count": 1187,
   "outputs": [],
   "source": [
    "def find_url_add_token(data):\n",
    "    '''\n",
    "    This function takes in a dataframe and returns a dataframe with the url token added.\n",
    "    ---\n",
    "    Parameters:\n",
    "        data: pandas dataframe\n",
    "    ---\n",
    "    Returns:\n",
    "        df: pandas dataframe\n",
    "    '''\n",
    "\n",
    "    data['url'] = None\n",
    "    for i, row in data.iterrows():\n",
    "        content = row['content']\n",
    "        url = re.findall(r'(https?://\\S+)', content)\n",
    "        if len(url) != 0:\n",
    "            data.at[i, 'url'] = url[0]\n",
    "            content = content.replace(url[0], ' [URL] ')\n",
    "            data.at[i, 'content'] = content"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-19T12:54:42.368065Z",
     "start_time": "2024-01-19T12:54:42.347181Z"
    }
   },
   "id": "6748271dd1612aac"
  },
  {
   "cell_type": "code",
   "execution_count": 1188,
   "outputs": [],
   "source": [
    "def get_tweets(df):\n",
    "    '''\n",
    "    This function takes in a dataframe and returns a dataframe with only tweets.\n",
    "    ---\n",
    "    Parameters:\n",
    "        df: pandas dataframe  \n",
    "    ---\n",
    "    Returns:\n",
    "        filtered_df: pandas dataframe\n",
    "    '''\n",
    "\n",
    "    # Assuming 'tweet/retweet' is the column name\n",
    "    filtered_df = df[df['tweet/retweet'] == 0].copy()\n",
    "\n",
    "    return filtered_df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-19T12:54:42.371810Z",
     "start_time": "2024-01-19T12:54:42.353573Z"
    }
   },
   "id": "99ca2c346e8b02e1"
  },
  {
   "cell_type": "code",
   "execution_count": 1189,
   "outputs": [],
   "source": [
    "def get_retweets(df):\n",
    "    '''\n",
    "    This function takes in a dataframe and returns a dataframe with only tweets.\n",
    "    ---\n",
    "    Parameters:\n",
    "        df: pandas dataframe  \n",
    "    ---\n",
    "    Returns:\n",
    "        filtered_df: pandas dataframe\n",
    "    '''\n",
    "\n",
    "    # Assuming 'tweet/retweet' is the column name\n",
    "    filtered_df = df[df['tweet/retweet'] == 1].copy()\n",
    "\n",
    "    return filtered_df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-19T12:54:42.399223Z",
     "start_time": "2024-01-19T12:54:42.376640Z"
    }
   },
   "id": "23209b75a068ab65"
  },
  {
   "cell_type": "code",
   "execution_count": 1190,
   "outputs": [],
   "source": [
    "def get_quotes(df):\n",
    "    '''\n",
    "    This function takes in a dataframe and returns a dataframe with only tweets.\n",
    "    ---\n",
    "    Parameters:\n",
    "        df: pandas dataframe  \n",
    "    ---\n",
    "    Returns:\n",
    "        filtered_df: pandas dataframe\n",
    "    '''\n",
    "\n",
    "    # Assuming 'tweet/retweet' is the column name\n",
    "    filtered_df = df[df['is_quote'] == 1].copy()\n",
    "\n",
    "    return filtered_df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-19T12:54:42.399434Z",
     "start_time": "2024-01-19T12:54:42.389778Z"
    }
   },
   "id": "64a9c24aa7dec91"
  },
  {
   "cell_type": "code",
   "execution_count": 1191,
   "outputs": [],
   "source": [
    "def convert_string_to_list_of_dicts(s):\n",
    "    try:\n",
    "        # Using ast.literal_eval to safely evaluate the string as a Python expression\n",
    "        list_of_dicts = ast.literal_eval(s)\n",
    "\n",
    "        # Ensure the result is a list of dictionaries\n",
    "        if not isinstance(list_of_dicts, list) or not all(isinstance(d, dict) for d in list_of_dicts):\n",
    "            raise ValueError(\"Input is not a valid string representation of a list of dictionaries\")\n",
    "\n",
    "        return list_of_dicts\n",
    "    except (SyntaxError, ValueError) as e:\n",
    "        # Handle exceptions if the string cannot be evaluated or converted\n",
    "        return []"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-19T12:54:42.419058Z",
     "start_time": "2024-01-19T12:54:42.402243Z"
    }
   },
   "id": "84117f68883a2a53"
  },
  {
   "cell_type": "code",
   "execution_count": 1192,
   "outputs": [],
   "source": [
    "def remove_hashtags(data):\n",
    "    '''\n",
    "    This function takes in a dataframe and returns a dataframe with the hashtags removed.\n",
    "    ---\n",
    "    Parameters:\n",
    "        df: pandas dataframe\n",
    "    ---\n",
    "    Returns:\n",
    "        df: pandas dataframe\n",
    "    '''\n",
    "\n",
    "    for i, row in data.iterrows():\n",
    "        if len(data.at[i, 'hashtags']) != 0:\n",
    "            hashtags = data.at[i, 'hashtags']\n",
    "            for hashtag in hashtags:\n",
    "                hashtag = '#' + hashtag['text']\n",
    "                data.at[i, 'content'] = data.at[i, 'content'].replace(hashtag, '[HASHTAG]')    "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-19T12:54:42.423716Z",
     "start_time": "2024-01-19T12:54:42.416360Z"
    }
   },
   "id": "760d23df461a46a7"
  },
  {
   "cell_type": "code",
   "execution_count": 1193,
   "outputs": [],
   "source": [
    "def count_mentions(data):\n",
    "    '''\n",
    "    This function takes in a dataframe and returns a dataframe with the frequency of mentions.\n",
    "    ---\n",
    "    Parameters:\n",
    "        data: pandas dataframe\n",
    "    ---\n",
    "    Returns:\n",
    "        df: pandas dataframe\n",
    "    '''\n",
    "\n",
    "    data['mentions count'] = None\n",
    "    for i, row in data.iterrows():\n",
    "        mentions = row['mentions']\n",
    "        data.at[i, 'mentions count'] = len(mentions)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-19T12:54:42.442724Z",
     "start_time": "2024-01-19T12:54:42.422155Z"
    }
   },
   "id": "ea278c3efa78d910"
  },
  {
   "cell_type": "code",
   "execution_count": 1194,
   "outputs": [],
   "source": [
    "def count_hashtags(data):\n",
    "    '''\n",
    "    This function takes in a dataframe and returns a dataframe with the frequency of hashtags.\n",
    "    ---\n",
    "    Parameters:\n",
    "        data: pandas dataframe\n",
    "    ---\n",
    "    Returns:\n",
    "        df: pandas dataframe\n",
    "    '''\n",
    "\n",
    "    data['hashtags count'] = None\n",
    "    for i, row in data.iterrows():\n",
    "        hashtags = row['hashtags']\n",
    "        data.at[i, 'hashtags count'] = len(hashtags)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-19T12:54:42.442885Z",
     "start_time": "2024-01-19T12:54:42.432461Z"
    }
   },
   "id": "be4ce880cb4b148b"
  },
  {
   "cell_type": "code",
   "execution_count": 1195,
   "outputs": [],
   "source": [
    "def remove_mentions(data):\n",
    "    '''\n",
    "    This function takes in a dataframe and returns a dataframe with the mentions removed.\n",
    "    ---\n",
    "    Parameters:\n",
    "        data: pandas dataframe\n",
    "    ---\n",
    "    Returns:\n",
    "        df: pandas dataframe\n",
    "    '''\n",
    "    for i, row in data.iterrows():\n",
    "        mentions = row['mentions']\n",
    "        if len(mentions) != 0:\n",
    "            for mention in mentions:\n",
    "                mention = '@' + mention\n",
    "                data.at[i, 'content'] = data.at[i, 'content'].replace(mention, '[MENTION]')\n",
    "        data.at[i, 'mentions'] = mentions"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-19T12:54:42.462558Z",
     "start_time": "2024-01-19T12:54:42.440263Z"
    }
   },
   "id": "d612c7e3525c2e3"
  },
  {
   "cell_type": "code",
   "execution_count": 1196,
   "outputs": [],
   "source": [
    "def identify_replies(data):\n",
    "    '''\n",
    "    This function takes in a dataframe and modifies it to identify replies. 1 inidicates that the tweet is a reply, 0 indicates that the tweet is not a reply.\n",
    "    ---\n",
    "    Parameters:\n",
    "        data: pandas dataframe\n",
    "    '''\n",
    "    data['Reply'] = None\n",
    "    for index, row in data.iterrows():\n",
    "        if row['content'].find('[MENTION]') == 0:\n",
    "            data.at[index, 'Reply'] = 1 # This is a reply\n",
    "        else:\n",
    "            data.at[index, 'Reply'] = 0"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-19T12:54:42.462668Z",
     "start_time": "2024-01-19T12:54:42.447414Z"
    }
   },
   "id": "7d45fb3a6f5e11e3"
  },
  {
   "cell_type": "code",
   "execution_count": 1197,
   "outputs": [],
   "source": [
    "def process_word(word):\n",
    "    if word.strip().isdigit():\n",
    "        return \" \"\n",
    "    # Use regex to find consecutive double or more letters at the end of the word\n",
    "    match = re.search(r'(\\w*?)(\\w)\\2+$', word)\n",
    "\n",
    "    if match:\n",
    "        # Replace the matched part with a single occurrence of the letter\n",
    "        modified_word = match.group(1) + match.group(2)\n",
    "        return modified_word\n",
    "    else:\n",
    "        # If no consecutive double or more letters found, return the original word\n",
    "        return word"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-19T12:54:42.463884Z",
     "start_time": "2024-01-19T12:54:42.456866Z"
    }
   },
   "id": "28cb7f565b767042"
  },
  {
   "cell_type": "code",
   "execution_count": 1198,
   "outputs": [],
   "source": [
    "def remove_double_letters(sentence):\n",
    "    # Split the sentence into a list of words\n",
    "    words = sentence.split()\n",
    "\n",
    "    # Process each word in the list\n",
    "    modified_words = [process_word(word) for word in words]\n",
    "    \n",
    "    emojis = []\n",
    "    \n",
    "    for i in range(len(modified_words)):\n",
    "        word = modified_words[i]\n",
    "        emoji_occ = emoji.emoji_list(word)\n",
    "        if len(emoji_occ) != 0:\n",
    "            for em in emoji_occ:\n",
    "                emojis.append(em['emoji'])\n",
    "                word = word[0:em['match_start']] + ' [EMOJI] ' + word[em['match_end']:]\n",
    "                modified_words[i] = word\n",
    "                \n",
    "\n",
    "    modified_words = [word for word in modified_words if not emoji.is_emoji(word)]\n",
    "\n",
    "    # Join the modified words back into a sentence\n",
    "    modified_sentence = ' '.join(modified_words)\n",
    "\n",
    "    return modified_sentence, emojis\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-19T12:54:42.488523Z",
     "start_time": "2024-01-19T12:54:42.466007Z"
    }
   },
   "id": "bd49ddd70180836c"
  },
  {
   "cell_type": "code",
   "execution_count": 1199,
   "outputs": [],
   "source": [
    "def clean_text(data: pd.DataFrame) -> pd.DataFrame:\n",
    "    # Define a function to replace contractions in a string\n",
    "    def replace_everything(s):\n",
    "        \n",
    "        if s.startswith('rt'):\n",
    "            s = s.replace('rt', ' ')\n",
    "            \n",
    "        for contraction, replacement in NON_SPACED_CONTRACTIONS.items():\n",
    "            s = s.replace(contraction, replacement)\n",
    "            \n",
    "        for contraction, replacement in CONTRACTIONS.items():\n",
    "            s = ' ' + s + ' '\n",
    "            s = s.replace(' ' + contraction + ' ', ' ' + replacement + ' ')\n",
    "            s = s.strip()\n",
    "\n",
    "        for i in UNNECESSARY_CHARACTERS:\n",
    "            s = s.replace(i, ' ')\n",
    "            \n",
    "        s, emojis = remove_double_letters(s)\n",
    "        \n",
    "        s = ' ' + s + ' '\n",
    "        \n",
    "        for abb in TEXTING_LANGUAGE:\n",
    "            s = s.replace(' ' + abb + ' ', ' ' + TEXTING_LANGUAGE[abb] + ' ')\n",
    "            \n",
    "        for word in STOPWORDS:\n",
    "            if word in s:\n",
    "                s = s.replace(' ' + word + ' ' , ' ')\n",
    "        \n",
    "        while  '  ' in s:\n",
    "            s = s.replace('  ', ' ')\n",
    "        \n",
    "        s = s.strip()\n",
    "        \n",
    "        return s, emojis\n",
    "    \n",
    "    # Apply the function to the 'content' column of the dataframe\n",
    "    content = [replace_everything(tweet)[0] for tweet in list(data['content'])]\n",
    "    emojis = [replace_everything(tweet)[1] for tweet in list(data['content'])]\n",
    "    data['content'] = content\n",
    "    data['emojis'] = emojis\n",
    "\n",
    "    return data\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-19T12:54:42.490462Z",
     "start_time": "2024-01-19T12:54:42.478676Z"
    }
   },
   "id": "db3078267f0ca2b6"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 4.1 Cleaning"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1ed7c408bb31c0d0"
  },
  {
   "cell_type": "code",
   "execution_count": 1201,
   "outputs": [],
   "source": [
    "circle_tweets_df['content'] = circle_tweets_df['content'].str.lower()\n",
    "circle_tweets_df['mentions'] = circle_tweets_df['mentions'].str.lower().apply(convert_string_to_list)\n",
    "tweets_df['content'] = tweets_df['content'].str.lower()\n",
    "tweets_df['mentions'] = tweets_df['mentions'].str.lower().apply(convert_string_to_list)\n",
    "circle_tweets_df['hashtags'] = circle_tweets_df['hashtags'].apply(convert_string_to_list)\n",
    "tweets_df['hashtags'] = tweets_df['hashtags'].str.lower().apply(convert_string_to_list_of_dicts)\n",
    "tweets_df['date'] = pd.to_datetime(tweets_df['date'], format='%Y-%m-%d')\n",
    "circle_tweets_df['date'] = pd.to_datetime(circle_tweets_df['date'], format='%Y-%m-%d')\n",
    "tweets_df['hour'] = tweets_df['hour'].astype(int)\n",
    "circle_tweets_df['hour'] = circle_tweets_df['hour'].astype(int)\n",
    "circle_tweets_df.drop(columns=['hashtags'], inplace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-19T12:54:42.632382Z",
     "start_time": "2024-01-19T12:54:42.491300Z"
    }
   },
   "id": "fa438ae2303d28d7"
  },
  {
   "cell_type": "code",
   "execution_count": 1202,
   "outputs": [],
   "source": [
    "find_url_add_token(circle_tweets_df)\n",
    "find_url_add_token(tweets_df)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-19T12:54:43.042281Z",
     "start_time": "2024-01-19T12:54:42.634715Z"
    }
   },
   "id": "37acf604483da75e"
  },
  {
   "cell_type": "code",
   "execution_count": 1203,
   "outputs": [],
   "source": [
    "remove_hashtags(tweets_df)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-19T12:54:43.396176Z",
     "start_time": "2024-01-19T12:54:43.052075Z"
    }
   },
   "id": "5d1136e16831c01e"
  },
  {
   "cell_type": "code",
   "execution_count": 1204,
   "outputs": [],
   "source": [
    "count_hashtags(tweets_df)\n",
    "count_mentions(tweets_df)\n",
    "count_mentions(circle_tweets_df)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-19T12:54:44.271182Z",
     "start_time": "2024-01-19T12:54:43.399774Z"
    }
   },
   "id": "1139411bf2088914"
  },
  {
   "cell_type": "code",
   "execution_count": 1205,
   "outputs": [],
   "source": [
    "remove_mentions(data=tweets_df)\n",
    "remove_mentions(data=circle_tweets_df)\n",
    "identify_replies(data=tweets_df)\n",
    "identify_replies(data=circle_tweets_df)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-19T12:54:45.287207Z",
     "start_time": "2024-01-19T12:54:44.272049Z"
    }
   },
   "id": "3d9676263dfe2c38"
  },
  {
   "cell_type": "code",
   "execution_count": 1206,
   "outputs": [],
   "source": [
    "tweets_df = clean_text(tweets_df)\n",
    "circle_tweets_df = clean_text(circle_tweets_df)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-19T12:54:49.209437Z",
     "start_time": "2024-01-19T12:54:45.297935Z"
    }
   },
   "id": "32c4503a806ef53b"
  },
  {
   "cell_type": "code",
   "execution_count": 1207,
   "outputs": [],
   "source": [
    "tweets_df['content'] = tweets_df['content'].fillna('').astype(str)\n",
    "circle_tweets_df['content'] = circle_tweets_df['content'].fillna('').astype(str)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-19T12:54:49.252999Z",
     "start_time": "2024-01-19T12:54:49.222502Z"
    }
   },
   "id": "30fb17f57dcdbe6c"
  },
  {
   "cell_type": "code",
   "execution_count": 1218,
   "outputs": [],
   "source": [
    "emojis_tweets_df = tweets_df.explode('emojis')\n",
    "emojis_tweets_df = emojis_tweets_df['emojis'].value_counts().reset_index()\n",
    "emojis_circle_df = circle_tweets_df.explode('emojis')\n",
    "emojis_circle_df = emojis_circle_df['emojis'].value_counts().reset_index()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-19T14:10:33.101271Z",
     "start_time": "2024-01-19T14:10:32.977351Z"
    }
   },
   "id": "bf693ef0698ca8cd"
  },
  {
   "cell_type": "code",
   "execution_count": 1222,
   "outputs": [],
   "source": [
    "emojis_tweets_df.to_csv('emojis_tweets.csv', index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-19T14:11:11.505080Z",
     "start_time": "2024-01-19T14:11:11.451586Z"
    }
   },
   "id": "13425d0a0c0d24c7"
  },
  {
   "cell_type": "code",
   "execution_count": 1223,
   "outputs": [],
   "source": [
    "tweets_only = get_tweets(df=tweets_df)\n",
    "retweets_only = get_retweets(df=tweets_df)\n",
    "quotes_only = get_quotes(df=tweets_df)\n",
    "circle_quotes = get_quotes(df=circle_tweets_df)\n",
    "tweet_quotes = get_quotes(df=tweets_only)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-19T14:11:16.256808Z",
     "start_time": "2024-01-19T14:11:16.129269Z"
    }
   },
   "id": "c0d063060192e337"
  },
  {
   "cell_type": "code",
   "execution_count": 1230,
   "outputs": [],
   "source": [
    "# Count the number of replies versus normal tweets\n",
    "reply_counts = tweets_only['Reply'].value_counts().reset_index()\n",
    "reply_counts.columns = ['Type', 'Count']"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-19T14:14:25.617031Z",
     "start_time": "2024-01-19T14:14:25.588516Z"
    }
   },
   "id": "12f8c613eab7f0b3"
  },
  {
   "cell_type": "code",
   "execution_count": 1231,
   "outputs": [],
   "source": [
    "reply_counts.at[0, 'Type'] = 'Normal Tweets'\n",
    "reply_counts.at[1, 'Type'] = 'Replies'"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-19T14:14:26.006695Z",
     "start_time": "2024-01-19T14:14:25.979688Z"
    }
   },
   "id": "c846a31a56eb846e"
  },
  {
   "cell_type": "code",
   "execution_count": 1233,
   "outputs": [],
   "source": [
    "reply_counts.to_csv('reply_counts_tweets.csv', index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-19T14:14:45.576405Z",
     "start_time": "2024-01-19T14:14:45.520552Z"
    }
   },
   "id": "fd89c51bd33f5068"
  },
  {
   "cell_type": "code",
   "execution_count": 1234,
   "outputs": [],
   "source": [
    "TWEET_TYPES = ['Original tweet', 'Reply', 'Quote', 'Retweet', 'Circle tweet', 'Circle quote']\n",
    "TWEET_COUNTS = [int(reply_counts.at[0,'Count']), int(reply_counts.at[1,'Count']), len(quotes_only), len(retweets_only), len(circle_tweets_df) -  len(circle_quotes), len(circle_quotes)]\n",
    "\n",
    "tweet_counts_df = pd.DataFrame({'Type': TWEET_TYPES, 'Count': TWEET_COUNTS})\n",
    "\n",
    "tweet_counts_df.to_csv('tweet_counts.csv', index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-19T14:18:32.072693Z",
     "start_time": "2024-01-19T14:18:31.970567Z"
    }
   },
   "id": "b383c03a13b2741e"
  },
  {
   "cell_type": "code",
   "execution_count": 1235,
   "outputs": [
    {
     "data": {
      "text/plain": "             Type  Count\n0  Original tweet   5821\n1           Reply   4993\n2           Quote    670\n3         Retweet   2069\n4    Circle tweet   1005\n5    Circle quote    108",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Type</th>\n      <th>Count</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Original tweet</td>\n      <td>5821</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Reply</td>\n      <td>4993</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Quote</td>\n      <td>670</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Retweet</td>\n      <td>2069</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Circle tweet</td>\n      <td>1005</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>Circle quote</td>\n      <td>108</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 1235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_counts_df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-19T14:18:37.692790Z",
     "start_time": "2024-01-19T14:18:37.621736Z"
    }
   },
   "id": "3c166ac7b6a760a3"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "ed2c5db60579f582"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
